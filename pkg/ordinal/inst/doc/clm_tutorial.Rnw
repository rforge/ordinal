\documentclass[a4paper]{article}
\usepackage{amsmath}%the AMS math extension of LaTeX.
\usepackage{amssymb}%the extended AMS math symbols.
%% \usepackage{amsthm}
\usepackage{bm}%Use 'bm.sty' to get `bold math' symbols
\usepackage{natbib}
\usepackage{Sweave}
\usepackage{url}
\usepackage{subfigure}
\usepackage{float}%Use `float.sty'
\usepackage[left=3.5cm,right=3.5cm]{geometry}
\usepackage{algorithmic}
\usepackage[amsmath,thmmarks,standard,thref]{ntheorem}

%%\VignetteIndexEntry{clm tutorial}
%%\VignetteDepends{ordinal, xtable}
\title{A Tutorial on fitting Cumulative Link Models with 
  %% \texttt{clmm} from 
  the \textsf{ordinal} Package} 
\author{Rune Haubo B Christensen}

%% \numberwithin{equation}{section}
\setlength{\parskip}{2mm}%.8\baselineskip}
\setlength{\parindent}{0in}

%%  \DefineVerbatimEnvironment{Sinput}{Verbatim}%{}
%%  {fontshape=sl, xleftmargin=1em}
%%  \DefineVerbatimEnvironment{Soutput}{Verbatim}%{}
%%  {xleftmargin=1em}
%%  \DefineVerbatimEnvironment{Scode}{Verbatim}%{}
%%  {fontshape=sl, xleftmargin=1em}
\fvset{listparameters={\setlength{\topsep}{0pt}}}
%% \fvset{listparameters={\setlength{\botsep}{0pt}}}
\renewenvironment{Schunk}{\vspace{-1mm}}{\vspace{-1mm}}

%RE-DEFINE marginpar
\setlength{\marginparwidth}{1in}
\let\oldmarginpar\marginpar
\renewcommand\marginpar[1]{\oldmarginpar[\-\raggedleft\tiny #1]%
{\tiny #1}}
%uncomment to _HIDE_MARGINPAR_:
%\renewcommand\marginpar[1]{}

\newcommand{\var}{\textup{var}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\bta}{\bm \theta}
\newcommand{\ta}{\theta}
\newcommand{\tah}{\hat \theta}
\newcommand{\di}{~\textup{d}}
\newcommand{\td}{\textup{d}}
\newcommand{\Si}{\Sigma}
\newcommand{\si}{\sigma}
\newcommand{\bpi}{\bm \pi}
\newcommand{\bmeta}{\bm \eta}
\newcommand{\tdots}{\hspace{10mm} \texttt{....}}
\newcommand{\FL}[1]{\fvset{firstline= #1}}
\newcommand{\LL}[1]{\fvset{lastline= #1}}
\newcommand{\s}{\square}
\newcommand{\bs}{\blacksquare}

% figurer bagerst i artikel
%% \usepackage[tablesfirst, nolists]{endfloat}
%% \renewcommand{\efloatseparator}{\vspace{.5cm}}

\theoremstyle{plain} %% {break}
\theoremseparator{:}
\theoremsymbol{{\tiny $\square$}}
%%\theoremstyle{plain}
\theorembodyfont{\small}
\theoremindent5mm
\renewtheorem{example}{Example}

%% \newtheoremstyle{example}{\topsep}{\topsep}%
%% {}%         Body font
%% {}%         Indent amount (empty = no indent, \parindent = para indent)
%% {\bfseries}% Thm head font
%% {}%        Punctuation after thm head
%% {\newline}%     Space after thm head (\newline = linebreak)
%% {\thmname{#1}\thmnumber{ #2}\thmnote{ #3}}%         Thm head spec
%% 
%% \theoremstyle{example}
%% %% \newtheorem{example}{Example}[subsection]
%% \newtheorem{example}{Example}[section]

\usepackage{lineno}
% \linenumbers
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
\expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
\expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
\renewenvironment{#1}%
{\linenomath\csname old#1\endcsname}%
{\csname oldend#1\endcsname\endlinenomath}}%
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
 \patchAmsMathEnvironmentForLineno{#1}%
 \patchAmsMathEnvironmentForLineno{#1*}}%
\AtBeginDocument{%
\patchBothAmsMathEnvironmentsForLineno{equation}%
\patchBothAmsMathEnvironmentsForLineno{align}%
\patchBothAmsMathEnvironmentsForLineno{flalign}%
\patchBothAmsMathEnvironmentsForLineno{alignat}%
\patchBothAmsMathEnvironmentsForLineno{gather}%
\patchBothAmsMathEnvironmentsForLineno{multline}%
}

\begin{document}
\bibliographystyle{chicago}
\maketitle

\begin{abstract}
  
  It is shown by example how a cumulative link mixed model is fitted
  with the \texttt{clm} function in package \textsf{ordinal}. Model
  interpretation and inference is briefly discussed.

\end{abstract}

%% \newpage
%% \tableofcontents
%% \newpage

\SweaveOpts{echo=TRUE, results=verb, width=4.5, height=4.5}
\SweaveOpts{prefix.string=figs}
\fvset{listparameters={\setlength{\topsep}{0pt}}, gobble=0, fontsize=\small}
%% \fvset{gobble=0, fontsize=\small}
\setkeys{Gin}{width=.49\textwidth}

<<Initialize, echo=FALSE, results=hide>>=

## Load common packages, functions and set settings:
library(ordinal)
library(xtable)
## 
RUN <- FALSE    #redo computations and write .RData files
## Change options:
op <- options() ## To be able to reset settings
options("digits" = 7)
options(help_type = "html")
## options("width" = 75)
options("SweaveHooks" = list(fig=function()
        par(mar=c(4,4,.5,0)+.5)))
options(continue=" ")

@

We will consider the data on the bitterness of wine from
\citet{randall89} presented in Table~\ref{tab:winedata} and available
as the object \texttt{wine} in package \textsf{ordinal}. The data were
also analyzed with mixed effects models by \citet{tutz96}.
The following gives an impression of the wine data object:
<<>>=
data(wine)
head(wine)
str(wine)
@ 
The data represent a factorial experiment on factors determining the
bitterness of wine with 1 = ``least bitter'' and 5 = ``most bitter''. 
Two treatment factors (temperature and contact)
each have two levels. Temperature and contact between juice and
skins can be controlled when crushing grapes during wine
production. Nine judges each assessed wine from two bottles from
each of the four treatment conditions, hence there are 72
observations in all. For more information see the manual entry for the
wine data: \texttt{help(wine)}.

\begin{table}
  \centering
  \caption{Ratings of the bitterness of some white wines. Data are
    adopted from \citet{randall89}.}  
  \label{tab:winedata}
  \begin{tabular}{lllrrrrrrrrr}
    \hline
    & & & \multicolumn{9}{c}{Judge} \\
    \cline{4-12}
<<echo=FALSE, results=tex>>=
data(wine)
temp.contact.bottle <- with(wine, temp:contact:bottle)[drop=TRUE]
tab <- xtabs(as.numeric(rating) ~ temp.contact.bottle + judge,
             data=wine) 
class(tab) <- "matrix"
attr(tab, "call") <- NULL
mat <- cbind(rep(c("cold", "warm"), each = 4),
             rep(rep(c("no", "yes"), each=2), 2),
             1:8, tab)
colnames(mat) <-
  c("Temperature", "Contact", "Bottle", 1:9)
xtab <- xtable(mat)
print(xtab, only.contents=TRUE, include.rownames=FALSE,
      sanitize.text.function = function(x) x)
@       
\end{tabular}
\end{table}

We will fit the following cumulative link mixed model to the wine
data: 
\begin{equation}
  \label{eq:CLM}
  \begin{array}{c}
    \textup{logit}(P(Y_i \leq j)) = \theta_j - \beta_1 (\mathtt{temp}_i)
    - \beta_2(\mathtt{contact}_i) \\
    i = 1,\ldots, n, \quad j = 1, \ldots, J-1
  \end{array}
\end{equation}
This is a model for the cumulative probability of the $i$th rating
falling in the $j$th category or below, where $i$ index
all observations and $j = 1, \ldots, J$ index the response
categories ($J = 5$). $\{\theta_j\}$ are known as threshold parameters
or cut-points. 

We fit this cumulative link model by maximum likelihood with the
\texttt{clm} function in package \textsf{ordinal}. Here we save the
fitted \texttt{clm} model 
in the object \texttt{fm1} (short for \texttt{f}itted \texttt{m}odel
\texttt{1}) and \texttt{print} the model by simply typing its name:
<<>>=
fm1 <- clm(rating ~ temp + contact, data=wine)
fm1
@ 
Additional information is provided with the \texttt{summary} method: 
<<>>=
summary(fm1)
@ 
The primary result is the coefficient table with parameter estimates,
standard errors and Wald (or normal) based $p$-values for tests of the
parameters being zero.
The maximum likelihood estimates of the parameters are:
\begin{equation}
  \label{eq:parameters}
  \hat\beta_1 = 2.50, ~~\hat\beta_2 = 1.53, 
  ~~\{\hat\theta_j\} = [-1.34,~ 1.25,~ 3.47,~ 5.01].
\end{equation}

The condition number of the Hessian measures the empirical
identifiability of the model. High numbers, say larger than $10^4$ or
$10^6$ indicate that the model is ill defined. This would indicate that
the model can be simplified, that possibly some parameters are not
identifiable, and that optimization of the model can be difficult. In
this case the condition number of the Hessian does not indicate a
problem with the model.

The coefficients for \texttt{temp} and \texttt{contact} are positive
indicating that higher temperature and more contact increase the
bitterness of wine, i.e., rating in higher categories is more likely. 
The odds ratio of the event $Y \geq j$ is
$\exp(\beta_{\textup{treatment}})$, thus the odds ratio of bitterness
being rated in 
category $j$ or above at warm relative to cold temperatures is 
<<>>=
exp(coef(fm1)[5])
@ 

The $p$-values for the location coefficients provided by the
\texttt{summary} method are based on the so-called Wald
statistic. More accurate test are provided by likelihood ratio
tests. These can be obtained with the \texttt{anova} method, for
example, the likelihood ratio test of \texttt{contact} is
<<>>=
fm2 <- clm(rating ~ temp, data=wine)
anova(fm2, fm1)
@ 
which in this case produce a slightly lower $p$-value.
Equivalently we can use \texttt{drop1} to obtain likelihood ratio
tests of the explanatory variables while \emph{controlling} for the
remaining variables:
<<>>=
drop1(fm1, test = "Chi")
@ 
Likelihood ratio tests of the explanatory variables while
\emph{ignoring} the remaining variables are provided by the
\texttt{add1} method:
<<>>=
fm0 <- clm(rating ~ 1, data=wine)
add1(fm0, scope = ~ temp + contact, test = "Chi")
@ 
In this case these latter tests are not as strong as the tests
controlling for the other variable.

Confidence intervals are provided by the \texttt{confint} method:
<<>>=
confint(fm1)
@ 
These are based on the profile likelihood function and generally
fairly accurate. Less accurate, but simple and symmetric confidence
intervals based on the standard errors of the parameters (so-called
Wald confidence intervals) can be obtained with
<<>>=
confint.default(fm1)
@ 

The cumulative link model in \eqref{eq:CLM} assume that the
thresholds, $\{\theta_j\}$ are constant for all values of the
remaining explanatory variables, here \texttt{temp} and
\texttt{contact}. This is generally referred to as the
\emph{proportional odds assumption} or \emph{equal slopes
  assumption}, while both names are not entirely adequate since the
assumption is also made for other links than the logit and for
categorical variables as well as continuous ones. We can relax that
assumption in two general ways: with nominal effects and scale effects
which we will now discuss in turn:

Nominal effects:

The CLM in \eqref{eq:CLM} specifies a structure in which the
regression parameters, $\bm\beta$ are not allowed to vary with $j$
alongas are the threshold parameters, $\bm\theta$. Nominal effects
relax this assumption by allowing one or more regression parameters to vary
with $j$. In the following model we allow the regression parameter for
\texttt{contact} to vary with $j$:
\begin{equation}
  \label{eq:CLM_nominal}
  \begin{array}{c}
    \textup{logit}(P(Y_i \leq j)) = \theta_j - \beta_1 (\mathtt{temp}_i)
    - \beta_{2j} (\mathtt{contact}_i) \\
    i = 1,\ldots, n, \quad j = 1, \ldots, J-1
  \end{array}
\end{equation}
This means that there is one estimate of $\beta_2$ for each $j$, i.e.,
for each of the five thresholds in addition to the estimates of
$\theta_j$ for each $j$. 
This model is specified as follows in \texttt{clm}:
<<>>=
fm.nom <- clm(rating ~ temp, nominal=~contact, data=wine)
summary(fm.nom)
@ 
As can be seen from the output of \texttt{summary} there is no
regression coefficient estimated for \texttt{contact}, but there are
two sets of threshold parameters estimated. 

The first five threshold
parameters have \texttt{.(Intercept)} appended their names indicating
that these are the estimates of $\theta_j$. 
The following five threshold parameters
have \texttt{.contactyes} appended their name indicating that these
parameters are differences between the threshold parameters at the two
levels of contact. This interpretation corresponds to the default
treatment contrasts; if other types of contrasts are specified, the
interpretation is a little different. 

We can perform a likelihood ratio test of the equal slopes or
proportional odds assumption for \texttt{contact} by comparing the
likelihoods of models \eqref{eq:CLM} and \eqref{eq:CLM_nominal} as
follows: 
<<>>=
anova(fm1, fm.nom)
@ 
There is only little difference in the log-likelihoods of the two
models, so the test is insignificant. There is therefore no evidence
that the proportional odds assumption is violated for
\texttt{contact}. 

It is not possible to estimate both $\beta_2$ and $\beta_{2j}$ in the
same model. Consequently variables that appear in \texttt{nominal}
cannot enter elsewhere as well. For instance not all parameters are
identifiable in the following model:
<<>>=
fm.nom2 <- clm(rating ~ temp + contact, nominal=~contact, data=wine)
@ 
We are made aware of this when summarizing or printing the model:
<<>>=
summary(fm.nom2)
@ 


Scale effects:

Scale effects are usually motivated from the latent variable
interpretation of a CLM. Assume the following model for a latent
variable:
\begin{equation}
  \label{eq:latent}
  S_i = \alpha + \bm x_i^T \bm\beta^* + \varepsilon_i, \quad
  \varepsilon_i \sim N(0, \sigma^{*^2})
\end{equation}
If the ordinal variable $Y_i$ is observed such that $Y_i = j$ is
recorded if $\theta_{j-1}^* < S_i \leq \theta_j^*$, where
\begin{equation}
  \label{eq:thresholds}
  -\infty \equiv \theta_0^* < \theta_1^* < \ldots < \theta^*_{J-1} <
  \theta_{J}^* \equiv \infty
\end{equation}
then we have the cumulative link model for $Y_i$:
\begin{equation*}
  P(Y_i \leq j) = \Phi ( \theta_j - \bm x_i^T \bm\beta )
\end{equation*}
where we have used $\theta_j = (\theta_j + \alpha) / \sigma$ and
$\bm\beta = \bm\beta^* / \sigma$, and $\Phi$ is the inverse probit
link and denotes the standard normal CDF. 
Other assumptions on the distribution of the latent variable, $S_i$
lead to other link functions. 

If the scale (or dispersion) of the latent distribution is described
by a log-linear model such that $\log( \sigma_i) = \bm z_i^T \bm
\zeta$, then the resulting CLM reads:
\begin{equation}
  \label{eq:CLM_scale}
  P(Y_i \leq j) = \Phi \left( \frac{\theta_j - \bm x_i^T \bm\beta}
    {\sigma_i} \right)
\end{equation}
Thus allowing for scale effects corresponds to modelling not only the
location of the latent distribution, but also the scale. If the link
function is the \texttt{probit}, the corresponding latent distribution
is Gaussian and the location equals the mean and scale or dispersion
equals the spread or standard deviation. 
Just as the absolute location ($\alpha$) is not identifiable, the
absolute scale ($\sigma$) is not identifiable either in the CLM. 

We can allow the scale of the latent distribution to depend on
temperature in the following way:
\begin{equation}
  \label{eq:CLM_nominal}
  \textup{logit}(P(Y_i \leq j)) = \frac{\theta_j - \beta_1 (\mathtt{temp}_i)
    - \beta_{2} (\mathtt{contact}_i)} {\exp( \zeta_1 (\mathtt{temp}_i))}
\end{equation}
\begin{equation*}
  i = 1,\ldots, n, \quad j = 1, \ldots, J-1  
\end{equation*}
We can estimate this model with 
<<>>=
fm.sca <- clm(rating ~ temp + contact, scale=~temp, data=wine)
summary(fm.sca)
@ 
Notice that both location and scale effects of \texttt{temp} are
identifiable. Also notice that coefficient is given on the
log-scale, where the Wald test is more appropriate. 
The absolute scale of the latent distribution is not estimable, but we
can estimate the scale at warm conditions relative to cold
conditions. Therefore the estimate of $\kappa$ in the relation
$\sigma_{warm} = \kappa \sigma_{cold}$ is given by  
<<>>=
exp(fm.sca$zeta)
@ 
However, the scale difference is not significant in this case. 

Confidence intervals can be obtained with:
<<>>=
confint(fm.sca, type = "profile")
@ 
Observe that the Wald intervals cannot be obtained (at least for the
scale parameters) with
<<>>=
confint.default(fm.sca)
@ 
but the following will provide them
<<>>=
confint(fm.sca, type = "Wald")
@ 

Model identifiability:

If we attempt to test the proportional odds assumption for
\texttt{temp}, some peculiarities show up:
<<>>=
fm.nom2 <- clm(rating ~ contact, nominal=~temp, data=wine)
summary(fm.nom2)
@ 
Observe that several of the threshold coefficients are extremely large
with huge standard errors. Also the condition number of the Hessian is
very large. These are all indications that the model is not
identifiable. The problem is revealed with
<<>>=
with(wine, table(temp, rating))
@ 
where the zeros indicate the problem. 
Nevertheless we can still test the proportional odds assumption for
\texttt{temp}: 
<<>>=
anova(fm1, fm.nom2)
@ 

\newpage
\bibliography{ordinal}
%% \newpage



\end{document}

<<misc, eval=FALSE, echo=FALSE>>=
@ 


